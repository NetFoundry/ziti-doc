
# Ziti Services

The primary strategy assumes that one function of Ziti is providing access to "services". A service encapsulates the definition of any
resource that could be accessed by a client on a traditional network. 

A service is defined by the following components:

* **Name** - the name of the service
* **Termination** - Ziti only provides access to a network service, it does not provide the service itself. The service must be able to get network traffic to whatever application or application cluster is actually providing the service, whether that provider has Ziti embedded or has no knowledge of Ziti
* **Configuration** - Ziti allows application specific configuration to be stored for services. See [Configuration Store](/docs/learn/core-concepts/config-store/overview)
* **Authorization** - For a details on controlling access to services, see [Policies](/docs/learn/core-concepts/security/authorization/policies/overview).

## Service Name
Ziti services must have names that are unique to their Ziti installation. Service names are how clients address services in order to consume them. Services which are provided by applications with Ziti embedded also use the service name to indicate which service is being provided.
  
Services defined on a Ziti Network have an almost limitless "namespace" available for identifying services. A Ziti service is to be defined by a name and this name is registered with the Ziti Controller. Once declared, services can then be addressed directly by name from Ziti-aware clients. This means there are effectively a **limitless** number names available with no need for global DNS registration. The names assigned are unique to a Ziti Network and the application developer has total control over service names.

## Service Termination
In Ziti, service termination refers to how a network traffic going over Ziti reaches the application (or application cluster) which is actually providing a service. There are a few basic ways in which a service can be terminated at an application.

There are some trade-offs to consider for each type of termination. 

1. Do you want end-to-end zero trust? If yes, that requires that both the client and server have Ziti identities and can connect securely with provisioned certificates.
1. Do you want Ziti to provide end-to-end encryption? Developers can always provide their own end-to-end encryption on top of the connectivity that Ziti provides, but not all modes of service termination allow Ziti to encrypt traffic end-to-end for you.
1. How accessible to non-zero trust clients do you want your server application to be? With the proper configuration applications can be fully 'dark', meaning they do not listen for connections.  

### SDK Embedded Applications
The server application can embed the Ziti Edge SDK. The application will have an enrolled identity and provisioned certificates. This has several advantages:

1. Connections between the application and Ziti will be secured using certificates. This enables true zero trust and end-to-end encrypted connections between SDK based clients and SDK based servers.
1. With an identity, the server application can participate in the Ziti security model. This means you can control which services the application can provide, and revoke access as needed. You can also control which edge routers the application may connect to.
1. The application will be 'dark'. Instead of listening for incoming network connections, the application will make an outgoing, secured connection to one or more Ziti edge routers. It will then receive network requests over these secured connections.

The downside to this approach, specifically for existing applications, is that the application must be refactored to use a Ziti Edge SDK. Depending on language and frameworks used, the effort required can range from updating a few lines of code to writing a new SDK from scratch for a language that's not supported yet.   

### Proxied Applications
For applications where it doesn't make sense to embed the SDK a Ziti SDK based proxy can provide access to the application. Often the proxy may take the form of a sidecar and be co-located with the application. This minimizes the attack surface. There are a few things to note about this approach.

1. The application will not be completely dark. It must accept connections from wherever the proxy is located. The proxy may be co-located with the application, so the attack surface area may be tiny. However, tiny is still bigger than zero.
1. Similarly, traffic can be encrypted between the client and the proxy, but traffic between the proxy and the application will not be covered under the Ziti end-to-end encryption. It may still be encrypted, if the client and server establish their own encryption at the discretion of the client and server implementors. 
1. Via the proxy, the application is still represented by an identity and thus participates in policies.

Services which use proxies for server side termination may require extra configuration, so that the proxying application knows how to connect to the server application. Service configurations are discussed more below.

### Ziti Router Terminated Services
Routers also have the ability to connect to applications providing services. This approach has its own advantages and disadvantages.

1. Like the proxy approach, the application cannot be completely dark. The application must be reachable from the Ziti router. 
2. Ziti currently only offers end-to-end encryption between two SDK applications. Sessions terminating at a router cannot be end-to-end encrypted by Ziti. The data may still be end-to-end encrypted by the client and server, but that is up to the client and server implementors.

### Summary

| Termination Type | End-to-end Zero Trust | Managed by Policies | Ziti Provided End-to-end encryption | Dark Server Application | 
| -----------------| ----------------------|---------------------|-------------------------------------|-------------------------|
| SDK Embedded     | Yes                   | Yes                 | Yes                                 | Yes                     |
| SDK Based Proxy  | No, only to proxy     | Yes (via Proxy)     | Only to proxy. If desired, full end-to-end must be done externally | No. Can be relatively locked down, though |
| Ziti Router      | No                    | No                  | No. If desired, end-to-end must be done externally | No. Can be relatively locked down, though. |

### Terminators
Terminators represent a way to connect to a specific server application for a specific service. 

For an SDK based server (whether embedded or proxied), these are created automatically as the application connects and removed when the application disconnects. 

For router terminated services they must be created manually. When creating a terminator manually, the following must be specified.

1. The router which will connect to the server application
1. The binding. This indicates which Xgress component on the router will handle making the connection. This will generally be `transport` for tcp based applications and `udp` for UDP based applications
    1. See the ziti-fabric documentation for more information on the Xgress framework
1. The address to connect to. This will generally take the form `<protocol>:<host or ip>:<port>`
    1. Example: `tcp:localhost:5432`

## Availability and Scaling
Services can be made highly available and/or horizontally scalable. There are two kinds of availability that server applications need to concern themselves with. 

### Router HA/Scaling 
The first is allowing multiple routers to connect to a single application. 

**Multiple Routers**

![image](/img/router-ha.png)

This ensures that the application will still be able to service requests even if a router fails or there is network partition separating a router and server application. It also will help ensure that the router layer doesn't become a bottleneck, as more routers can be added as necessary to scale out connectivity. Finally, it provides multiple network paths to the application. This gives smart routing more to choose optimal routes from as network conditions change.

### Application HA/Scaling
The second is application availability and/or scalability. There will often be multiple instances of a service application running, either for failover or in a load balanced deployment.

**Failover Deployment**

![image](/img/application-ha.png)

**Horizontal Scale Deployment**

![image](/img/horizontal-scale.png)

### Xt
All types of availability and scalability involve multiple terminators. What distinguishes an HA failover setup from a load-balanced horizontal scale setup is how new sessions are assigned to terminators. For failover, we want sessions to always go to the same service instance. For horizontal scale, we want to load balance sessions across available instances. 

The fabric contains a framework called Xt (eXtensible Terminators) which allows defining terminator strategies and defines how terminator strategies and external components integrate with smart routing. The general flow of terminator selection goes as follows:

  1. A client requests a new session for a service
  1. Smart routing finds all the active terminators for the session (active meaning the terminator's router is connected)
  1. Smart routing calculates a cost for each terminator then hands the service's terminator strategy a list of terminators and their costs ranked from lowest to highest
  1. The strategy returns the terminator that should be used
  1. A new session is created using that path. 
  
Strategies will often work by adjusting terminator costs. The selection algorithm then simply returns the lowest cost option presented by smart routing. 

#### Costs
There are a number of elements which feed the smart routing cost algorithm.

##### Route Cost
The cost of the route from the initiating route to the terminator router will be included in the terminator cost. This cost may be influenced by things such as link latencies and user determined link costs.

##### Static Cost
Each terminator has a static cost which can be set or updated when the terminator is created. SDK applications can set the terminator cost when they invoke the Listen operation.

#### Precedence
Each terminator has a precedence. There are three precedence levels: `required`, `default` and `failed`.
  
Smart routing will always rank terminators with higher precedence levels higher than terminators with lower precedence levers. So required terminators will always be first, default second and failed third. Precedence levels can be used to implement HA. The primary will be marked as required and the secondary as default. When the primary is determined to be down, either by some internal or external set of heuristics, it will be marked as Failed and new sessions will go to the secondary. When the primary recovers it can be bumped back up to Required.

##### Dynamic Cost 
Each terminator also has a dynamic cost that will move a terminator up and down relative to its precedence. This cost can be driven by strategies or by external components. A strategy might use number of active of open sessions or dial successes and failures to drive the dynamic cost.

##### Effective Cost

Each terminator has an associated precedence and dynamic cost. This can be reduced to a single cost. The cost algorithm ensures terminators at different precedence levels do not overlap. So a terminator which is marked failed, with dynamic cost 0, will always have a higher calculated cost than a terminator with default precedence and maximum value for dynamic cost. 

#### Strategies
The fabric currently provides four strategy implementations.

##### `smartrouting`
This is the default strategy. It always uses the lowest cost terminator. It drives costs as follows:

  * Cost is proportional to number of open sessions
  * Dial failures drive the cost up
  * Dial successes drive the cost down, but only as much as they were previously driven up by failures
  
##### `weighted`
This strategy drives costs in the same way as the `smartrouting` strategy. However instead of always picking the lowest cost terminator it does a weighted random selection across all terminators of the highest precedence. If a terminator has double the cost of another terminator it should get picked approximately half as often. 
   
##### `random`
This strategy does not change terminator weights. It does simple random selection across all terminators of the highest precedence. 

## Practical Service Hosting

### Edge Router Tunneler Hosting

#### Single Application Endpoint
When hosting services with the edge router tunneler (ER/T) combination you'll need to use a service configurations. We're going
to start off simply, with one service endpoint and build up from there.

Our application server is going to be on a local subnet at IP 192.168.3.136, port 8080. For our `test` service, we make
 and initial service configuration using the CLI as follows:

```
ziti edge create config test-host-config host.v2 '
{
    "terminators" : [
        {
            "address": "192.168.3.136",
            "port" : 8080,
            "protocol": "tcp"
        },
    ]
}
'

ziti edge create service test -c test-host-config --terminator-strategy smartrouting

ziti edge create edge-router edge-router-1 --tunneler-enabled
ziti edge create edge-router edge-router-2 --tunneler-enabled

# skipping router enrollment steps

ziti edge update identity edge-router-1 --role-attributes 'test-host'
ziti edge update identity edge-router-2 --role-attributes 'test-host'

ziti edge create service-edge-router-policy test-serp --service-roles '@test' --edge-router-roles '#all'
ziti edge create service-policy test-bind Bind --service-roles '@test' --identity-roles '#test-host'
```

This will provide basic access to the service with one or many ER/Ts. All edge routers are hitting the same endpoint,
so they don't need any customized configurations. Each ER/T hosting the service will create a terminator for the service
and traffic will get load-balanced across them.

#### Setting Per-Identity Precedence and Cost
If you're hosting this service on multiple ER/Ts but want to give preference to one or more of the, you can use cost
and precedence to do so. With our two ER/Ts, `edge-router-1` and `edge-router-2` if we want all traffic to go to
`edge-router-1` unless it's not available, we can set the service precedence for the identity as follows:

```
ziti edge update identity edge-router-1 --service-precedences test=required
```

If instead you just want to give the terminator on `edge-router-2` a higher cost, so it gets used less often, you
can do that as follows:

```
ziti edge update identity edge-router-2 --service-costs test=100
```

The default cost and precedence for an identity can also be set.

```
ziti edge update identity edge-router-1 --default-hosting-precedence required --default-hosting-cost 100
```

#### Multiple Application Endpoints
Next, let us add a second application endpoint. We want traffic load-balanced across the endpoints equally. We're going
to do this by adding the second endpoint to the configuration.

```
ziti edge update config test-host-config host.v2 --data '
{
    "terminators" : [
        {
            "address": "192.168.3.136",
            "port" : 8080,
            "protocol": "tcp"
        },
        {
            "address": "192.168.3.137",
            "port" : 8080,
            "protocol": "tcp"
        }
    ]
}
'
```

Now each ER/T will create two terminators, one for each endpoint, for a total of four terminators. Now that we have
multiple endpoints we'll want to know when they are healthy or unavailable we can use the just the endpoints which
are working. We can accomplish this by adding health checks to the configuration.

```
ziti edge update config test-host-config host.v2 --data '
{
    "terminators" : [
        {
            "address": "192.168.3.136",
            "port" : 8080,
            "protocol": "tcp",
            "portChecks" : [
                {
                    "address" : "192.168.3.136:8080",
                    "interval" : "5s",
                    "timeout" : "100ms",
                    "actions" : [
                        {
                            "trigger" : "fail",
                            "consecutiveEvents" : 3,
                            "action" : "mark unhealthy"
                        },
                        {
                            "trigger" : "pass",
                            "consecutiveEvents" : 3,
                            "action" : "mark healthy"
                        }
                ]
            }
            ]
        },
        {
            "address": "192.168.3.137",
            "port" : 8080,
            "protocol": "tcp",
            "portChecks" : [
                {
                    "address" : "192.168.3.137:8080",
                    "interval" : "5s",
                    "timeout" : "100ms",
                    "actions" : [
                        {
                            "trigger" : "fail",
                            "consecutiveEvents" : 3,
                            "action" : "mark unhealthy"
                        },
                        {
                            "trigger" : "pass",
                            "consecutiveEvents" : 3,
                            "action" : "mark healthy"
                        }
                    ]
                }
            ]
        }
    ]
}
'
```

Our configuration has gotten quite large! However, we've gained a good bit of functionality with our new additions.
Our servers will now be pinged every five seconds. If a the health check fails three times in a row, the associated
terminator will be marked unhealthy, which means its precedence will be set to `failed`. If subsequently the health check
passes three times in a row, its precedence will be reset to its original value.

This example uses simple port checks, but http checks are also supported. The checks are per-terminator, so if the
network fails between `edge-router-1` and the first application endpoint, that terminator will be marked as failed.
However, if `edge-router-2` can still reach it, then that terminator will remain in `default` or `required`, depending
on how it's configured.

At this point we have multiple ER/Ts and multiple application endpoints thereby removing all single points of failures.
This setup should work well for applications which are horizontally scalable.

#### Health Checks

There are two kinds of health checks supported, port check and http checks.

**Port Checks**

Port checks just check if a given port is accepting connections. They don't attempt to send or receive any data. They
support the following properties:

* `address` - an IP or DNS address with port.
    * This field is required.
    * Example: `192.168.1.100:8080`
    * Example: `myserver.com:8080`
* `interval` - how often to run the health check.
    * This field is required.
    * Example: `5s` (5 seconds)
    * Example: `1m` (1 minute)
    * Example: `250ms` (250 milliseconds)
* `timout` - the connection timeout. Uses same format as interval.
    * This field is required.
    * Example: `10s` (10 seconds)
* `actions` - how to react to health check result. Covered in more detail below.

**HTTP Checks**

HTTP Checks make a call to an HTTP endpoint. They support submitting a static body and checking the check results. They
support the following properties:

* `url` - the URL to connect to.
    * This field is required.
* `method` - the method to use. Valid values include `GET`, `PUT`, `POST`, `PATCH`.
    * This field is optional and defaults to `GET`.
* `body` - the data to submit in the body of the HTTP request.
    * This field is optional and defaults to an empty string.
* `expectStatus` - the response status code to expect. The check will fail if a different status code is encountered.
    * This field is optional and defaults to `200`.
* `expectInBody` - a string to expect in the status code response. The check will fail if the string is not found.
    * This field is optional. If not specified, the response body will not be checked.
* `interval` - how often to run the health check.
    * This field is required.
    * Example: `5s` (5 seconds)
    * Example: `1m` (1 minute)
    * Example: `250ms` (250 milliseconds)
* `timout` - the connection timeout. Uses same format as interval.
    * This field is required.
    * Example: `10s` (10 seconds)
* `actions` - how to react to health check result. Covered in more detail below.

**Actions**

Actions define how health checks results should be reacted to. Each check may have multiple actions. Actions support
the following properties:

* `trigger` - which kind of health check result to react to. Valid values include `pass`, `fail` and `change`.
    * This field is required
    * `change` is when the status changes from `pass` to `fail` or vice-versa.
* `duration` - only trigger the action if the trigger state has existed for the given duration.
    * This field is optional. If not specified, the duration is not checked.
    * Example: `30s` (30 seconds)
    * Use with `change` trigger events is not recommended.
* `consecutiveEvents` - the number of consecutive results of the given trigger type before executing the action.
    * This field is optional and defaults to 1
    * Use with `change` trigger events is not recommended.
* `action` - the action to take when the prerequisites defined by `trigger`, `duration` and `consecutiveEvents` are met.
    * This field is required
    * Valid actions include:
        * `mark unhealthy` - sets the associated terminator's precedence to `failed`.
        * `mark healthy` - sets the associated terminator's precedence back from `failed` to its original value.
        * `increase cost N` - increases the cost of the associated terminator by `N`.
        * `decrease cost N` - decreases the cost of the associated terminator by `N`.
        * `send event` - causes a terminator event to be emitted from the controller. Useful for alerting or external integrations.

**NOTE**

Although multiple health checks can be configured, it's best if the actions don't overlap. If you have two health
checks both changing the health status, the behavior when one check is passing and another is failing is undefined.
It should generally be safe to have multiple checks adjusting cost or generating events.

#### Active/Passive Fail-over

We may also setups with primary and fail-over instances. These can be configured by setting the precedence in the
config, rather than on the identity, as follows:

```
ziti edge update config test-host-config host.v2 --data '
{
    "terminators" : [
        {
            "address": "192.168.3.136",
            "port" : 8080,
            "protocol": "tcp",
            "portChecks" : [ "health check definitions not shown for brevity" ],
            "listenOptions" : {
                "precedence" : "required"
            }
        },
        {
            "address": "192.168.3.137",
            "port" : 8080,
            "protocol": "tcp",
            "portChecks" : [ "health check definitions not shown for brevity" ],
            "listenOptions" : {
                "precedence" : "default"
            }
        }
    ]
}
'
```

We've skipped the health checks in this example in order to highlight the important change, namely the addition of the
`listenOptions` section. Our first terminator is set to `required` and the second is set to `default`. Should the
health check for the primary endpoint fail, the terminator precedence will be dropped to `failed` and new traffic will
start flowing to the fail-over server. Should the primary recover, the health check will detect this and the precedence
will be reset to `required`.

Note that in addition to precedence, cost may also be set in the `listenOptions`.


### Standalone Tunneler Hosting
Most of the above applies to standalone tunnelers as well. The primary difference is in placement. Generally a tunneler
will be running on the same machine as the application server. This means that you'd have two tunnelers running, one on
each of the hosts. Your configuration could then reference `localhost`, allowing you to only define a single terminator
in your host config. In that case your configuration might looking something like the following:

```
ziti edge update config test-host-config host.v2 --data '
{
    "terminators" : [
        {
            "address": "localhost",
            "port" : 8080,
            "protocol": "tcp",
            "portChecks" : [
                {
                    "address" : "localhost:8080",
                    "interval" : "5s",
                    "timeout" : "100ms",
                    "actions" : [
                        {
                            "trigger" : "fail",
                            "consecutiveEvents" : 3,
                            "action" : "mark unhealthy"
                        },
                        {
                            "trigger" : "pass",
                            "consecutiveEvents" : 3,
                            "action" : "mark healthy"
                        }
                    ]
                }
            ]
        }
    ]
}
'
```

For fail-over setups, you would set the precedence on the identity, rather than in the configuration.

### SDK Hosted

SDK hosted applications do not require any configs. When they bind a service, a terminator is created on their behalf.
The SDKs have controls allowing cost and precedence to be set from the hosting application. Finally, the connection to
the edge router acts as a built in health check. If the SDK loses its connection to the edge router, the edge router will
remove any associated terminators. When the SDK reconnects, it will re-bind and a new terminator will be established.

### Other Health Check Options

If the health checks provided by `host.v2` configs are not adequate, there are a few options.

1. You can write a custom proxy using one of the SDKs. This would let you adjust cost and precedence based on your own,
arbitrarily complex health checks.
2. You could write a sidecar which runs the health checks and translates those into an HTTP health check that the tunnelers
can understand.